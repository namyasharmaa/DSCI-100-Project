{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(readxl)\n",
    "library(dplyr)\n",
    "library(gridExtra)\n",
    "options(repr.matrix.max.rows = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00257/Data_User_Modeling_Dataset_Hamdi%20Tolga%20KAHRAMAN.xls\"\n",
    "download.file(url, \"data.xls\")\n",
    "training_data <- read_excel(\"data.xls\", sheet = 2) # sheet 2 => training data\n",
    "testing_data <- read_excel(\"data.xls\", sheet = 3) # sheet 3 => testing data\n",
    "\n",
    "\n",
    "# select only the columns we need and making our class as a factor\n",
    "training_data <- training_data %>%\n",
    "    select(1:6) %>%\n",
    "    mutate(UNS = as_factor(UNS))\n",
    "\n",
    "testing_data <- testing_data %>%\n",
    "    select(1:6) %>%\n",
    "    mutate(UNS = as_factor(UNS))\n",
    "\n",
    "#training_data\n",
    "# testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "# split the data into 5 folds\n",
    "data_vfold <- vfold_cv(training_data, v = 5, strata = UNS)\n",
    "\n",
    "# scale and center our data\n",
    "data_recipe <- recipe(UNS ~ PEG, data = training_data) %>%\n",
    "  step_scale(all_predictors()) %>%\n",
    "  step_center(all_predictors())\n",
    "\n",
    "# create model specification\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "  set_engine(\"kknn\") %>%\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# set up differnt K\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 100, by = 5))\n",
    "\n",
    "# predict?\n",
    "knn_results <- workflow() %>%\n",
    "  add_recipe(data_recipe) %>%\n",
    "  add_model(knn_spec) %>%\n",
    "  tune_grid(resamples = data_vfold, grid = k_vals) %>%\n",
    "  collect_metrics() \n",
    "\n",
    "# get our accuracies\n",
    "accuracies <- knn_results %>%\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "# plot accuracy vs K and decide on K\n",
    "accuracy_vs_k <- ggplot(accuracies, aes(x = neighbors, y = mean)) +\n",
    "  geom_point() +\n",
    "  geom_line() +\n",
    "  labs(x = \"Neighbors\", y = \"Accuracy Estimate\")\n",
    "\n",
    "# accuracy_vs_k\n",
    "\n",
    "best_k <- accuracies %>%\n",
    "    select(mean, neighbors) %>%\n",
    "    arrange(desc(mean)) %>%\n",
    "    slice(1)\n",
    "\n",
    "# best_k\n",
    "# the best K is 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we know our K = 11, we train the model again using K = 11\n",
    "\n",
    "# make four new observations of different PEGs (exam scores)\n",
    "high <- tibble(PEG = 0.7)\n",
    "mid <- tibble(PEG = 0.4)\n",
    "low <- tibble(PEG = 0.2)\n",
    "very_low <- tibble(PEG = 0.0)\n",
    "\n",
    "# make model specification using 11 neighbors\n",
    "knn_spec <- nearest_neighbor(weight_func = 'rectangular', neighbors = 11) %>%\n",
    "    set_engine('kknn') %>%\n",
    "    set_mode('classification')\n",
    "\n",
    "# fit model specification to our training data\n",
    "knn_fit <- knn_spec %>%\n",
    "    fit(UNS ~ PEG, data = training_data)\n",
    "\n",
    "# predict all four made up values\n",
    "# predict(knn_fit, high)\n",
    "# predict(knn_fit, mid)\n",
    "# predict(knn_fit, low)\n",
    "# predict(knn_fit, very_low)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to display each UNS as a bar on x- axis \n",
    "# and their average PEG on the y-axis\n",
    "\n",
    "average_UNS <- training_data %>%\n",
    "    select('UNS', 'PEG') %>% # select the columns we need\n",
    "    group_by(UNS) %>% # group_by each UNS class\n",
    "    summarize(average_PEG = mean(PEG)) %>% # find the average PEG\n",
    "    arrange(desc(average_PEG))\n",
    "\n",
    "# plot the bars, re-ordering the bars in increasing order\n",
    "plot <- average_UNS %>%\n",
    "    ggplot(aes(fct_reorder(UNS, average_PEG), average_PEG, fill = UNS)) +\n",
    "    geom_bar(position = 'stack', stat = 'identity') + \n",
    "    geom_hline(yintercept = high[[1]], col = 'Green') +\n",
    "    geom_hline(yintercept = mid[[1]], col = 'Purple') +\n",
    "    geom_hline(yintercept = low[[1]], col = 'Cyan') +\n",
    "    geom_hline(yintercept = very_low[[1]], col = 'Red') +\n",
    "    geom_text(aes(1, high[[1]] + 0.01, label = 'UNS = High')) +\n",
    "    geom_text(aes(1, mid[[1]] + 0.01, label = 'UNS = Mid')) +\n",
    "    geom_text(aes(1, low[[1]] + 0.01, label = 'UNS = Low')) +\n",
    "    geom_text(aes(1, very_low[[1]] + 0.01, label = 'UNS = Very low')) +\n",
    "    xlab('User knowledge level (UNS)') +\n",
    "    ylab('Average exam score (PEG)') +\n",
    "    ggtitle('User knowledge levels average exam scores')\n",
    "    \n",
    "# average_UNS\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
